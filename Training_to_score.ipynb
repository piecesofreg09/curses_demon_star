{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import All Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import pickle, os, math\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400001, 162)\n",
      "Wall time: 1.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_dir = os.path.join(os.curdir, 'Data', 'Score', 'data_pics.pkl')\n",
    "with open(data_dir, 'rb') as in_file:\n",
    "    ot = pickle.load(in_file)\n",
    "data_pics = ot['data']\n",
    "target_pics = ot['target']\n",
    "print(data_pics.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the case of survival training, score training also has unbalanced class, the ratio of class 0 to 1 is almost 14:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360000, 162)\n",
      "class 0 has 335342 points\n",
      "class 1 has 24658 points\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_pics, target_pics, test_size=0.1, random_state=152)\n",
    "print(X_train.shape)\n",
    "X_train_train, X_vali, y_train_train, y_vali = train_test_split(\n",
    "    X_train, y_train, test_size=0.3, random_state=15545)\n",
    "print('class 0 has ' + str(len(y_train.index[y_train[0] == 0].tolist())) + ' points')\n",
    "print('class 1 has ' + str(len(y_train.index[y_train[0] == 1].tolist())) + ' points')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a balanced dataset, use all class 1 and randomly select the same of number class 0 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24658 + 24658 = 49316\n"
     ]
    }
   ],
   "source": [
    "index_0 = y_train.index[y_train[0] == 0].tolist()\n",
    "index_1 = y_train.index[y_train[0] != 0].tolist()\n",
    "index_0_comparable_to_1 = np.random.choice(index_0, math.floor(len(index_1) * 1))\n",
    "samples = np.concatenate([index_1, index_0_comparable_to_1])\n",
    "print(str(len(index_1)) + ' + ' + str(len(index_0_comparable_to_1)) + ' = ' + str(len(samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = new_data_df.iloc[samples, :]\n",
    "small_target = target_pics.iloc[samples, :]\n",
    "\n",
    "X_train_small, X_test_small, y_train_small, y_test_small = train_test_split(\n",
    "    small_data, small_target, test_size=0.3, random_state=1152)\n",
    "X_train_train_small, X_vali_small, y_train_train_small, y_vali_small = train_test_split(\n",
    "    X_train_small, y_train_small, test_size=0.3, random_state=8155)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ravelling the target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_small_m = np.ravel(y_train_small)\n",
    "y_test_small_m = np.ravel(y_test_small)\n",
    "y_train_train_small_m = np.ravel(y_train_train_small)\n",
    "y_vali_small_m = np.ravel(y_vali_small)\n",
    "y_train_m = np.ravel(y_train)\n",
    "y_test_m = np.ravel(y_test)\n",
    "y_train_train_m = np.ravel(y_train_train)\n",
    "y_vali_m = np.ravel(y_vali)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5237580263602568"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_sc = SVC(C=10.0, gamma='auto', kernel='rbf', verbose=True)\n",
    "clf_sc.fit(X_train_small, y_train_small_m)\n",
    "clf_sc.score(X_test_small, y_test_small_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9539033457249071\n"
     ]
    }
   ],
   "source": [
    "ypred = clf_sc.predict(X_test_small)\n",
    "print(sum(ypred) / len(ypred))\n",
    "test = [idd for idd, value in enumerate(ypred) if value == 0 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Layer Perceptor Classifier\n",
    "\n",
    "MLPC apparently failed at generalizing the inner trend, all the predictions turne out to be all 0 or all 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 5.89562739\n",
      "Iteration 2, loss = 0.75283252\n",
      "Iteration 3, loss = 0.71505717\n",
      "Iteration 4, loss = 0.71154901\n",
      "Iteration 5, loss = 0.71145618\n",
      "Iteration 6, loss = 0.71114702\n",
      "Iteration 7, loss = 0.71182472\n",
      "Iteration 8, loss = 0.71251703\n",
      "Iteration 9, loss = 0.71233927\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5042244001351808"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpc_sc = MLPClassifier(hidden_layer_sizes=(100, 50, 40, 20),\n",
    "                        alpha=0.15, max_iter=1000, batch_size=1000,\n",
    "                        verbose=True, learning_rate_init=0.01, tol=1e-5,\n",
    "                        learning_rate='adaptive')\n",
    "\n",
    "mlpc_sc.fit(X_train_small, y_train_small_m)\n",
    "mlpc_sc.score(X_test_small, y_test_small_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6161541061169314"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = mlpc_sc.predict(X_test_small)\n",
    "sum(ypred) / len(ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently the score is really low.\n",
    "\n",
    "Try to clip the data to reduce the number of freedom to avoid over fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49316, 162)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(small_data.iloc[:, 161])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 49316/49316 [01:29<00:00, 551.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_data = []\n",
    "window_size = 5\n",
    "for i in tqdm(range(small_data.shape[0])):\n",
    "    left = int(small_data.iloc[i, 161] - window_size)\n",
    "    right = int(small_data.iloc[i, 161] + window_size)\n",
    "    new_data.append(small_data.iloc[i, (2 * left):(2 * right + 2)].values.tolist() + small_data.iloc[i, 160:].values.tolist())\n",
    "new_data_df = pd.DataFrame(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49316, 24)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_ind = 2 * (small_data.iloc[:, 161] - window_size)\n",
    "right_ind = 2 * (small_data.iloc[:, 161] + window_size) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49316, 162)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_df\n",
    "\n",
    "X_train_small_short, X_test_small_short, y_train_small_short, y_test_small_short = train_test_split(\n",
    "    new_data_df, small_target, test_size=0.3, random_state=1152)\n",
    "X_train_train_small_short, X_vali_small_short, y_train_train_small_short, y_vali_small_short = train_test_split(\n",
    "    X_train_small_short, y_train_small_short, test_size=0.3, random_state=8155)\n",
    "\n",
    "y_train_small_short_m = np.ravel(y_train_small_short)\n",
    "y_test_small_short_m = np.ravel(y_test_small_short)\n",
    "y_train_train_small_short_m = np.ravel(y_train_train_small_short)\n",
    "y_vali_small_short_m = np.ravel(y_vali_small_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5891855356539372"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_sc_short = SVC(C=10.0, gamma='auto', kernel='rbf', verbose=True)\n",
    "clf_sc_short.fit(X_train_small_short, y_train_small_short_m)\n",
    "clf_sc_short.score(X_test_small_short, y_test_small_short_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99812, 221)\n",
      "(89830, 221)\n",
      "class 0 has 85117 points\n",
      "class 1 has 4713 points\n",
      "4713 + 4713 = 9426\n",
      "Wall time: 756 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_dir = os.path.join(os.curdir, 'Data', 'Score', 'data_basic.pkl')\n",
    "with open(data_dir, 'rb') as in_file:\n",
    "    ot = pickle.load(in_file)\n",
    "data_pics = ot['data']\n",
    "target_pics = ot['target']\n",
    "print(data_pics.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_pics, target_pics, test_size=0.1, random_state=152)\n",
    "print(X_train.shape)\n",
    "X_train_train, X_vali, y_train_train, y_vali = train_test_split(\n",
    "    X_train, y_train, test_size=0.3, random_state=15545)\n",
    "print('class 0 has ' + str(len(y_train.index[y_train[0] == 0].tolist())) + ' points')\n",
    "print('class 1 has ' + str(len(y_train.index[y_train[0] == 1].tolist())) + ' points')\n",
    "\n",
    "index_0 = y_train.index[y_train[0] == 0].tolist()\n",
    "index_1 = y_train.index[y_train[0] != 0].tolist()\n",
    "index_0_comparable_to_1 = np.random.choice(index_0, math.floor(len(index_1) * 1))\n",
    "samples = np.concatenate([index_1, index_0_comparable_to_1])\n",
    "print(str(len(index_1)) + ' + ' + str(len(index_0_comparable_to_1)) + ' = ' + str(len(samples)))\n",
    "\n",
    "\n",
    "small_data = data_pics.iloc[samples, :]\n",
    "small_target = target_pics.iloc[samples, :]\n",
    "\n",
    "X_train_small, X_test_small, y_train_small, y_test_small = train_test_split(\n",
    "    small_data, small_target, test_size=0.3, random_state=1152)\n",
    "X_train_train_small, X_vali_small, y_train_train_small, y_vali_small = train_test_split(\n",
    "    X_train_small, y_train_small, test_size=0.3, random_state=8155)\n",
    "\n",
    "y_train_small_m = np.ravel(y_train_small)\n",
    "y_test_small_m = np.ravel(y_test_small)\n",
    "y_train_train_small_m = np.ravel(y_train_train_small)\n",
    "y_vali_small_m = np.ravel(y_vali_small)\n",
    "y_train_m = np.ravel(y_train)\n",
    "y_test_m = np.ravel(y_test)\n",
    "y_train_train_m = np.ravel(y_train_train)\n",
    "y_vali_m = np.ravel(y_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6135077793493635"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_st = SVC(C=10.0, gamma='auto', kernel='rbf', verbose=True)\n",
    "clf_st.fit(X_train_small, y_train_small_m)\n",
    "clf_st.score(X_test_small, y_test_small_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5144978783592645"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = clf_st.predict(X_test_small)\n",
    "sum(ypred) / len(ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 529, 1735,  564], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(ypred - y_test_small_m + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.75222415\n",
      "Iteration 2, loss = 0.70612536\n",
      "Iteration 3, loss = 0.69621845\n",
      "Iteration 4, loss = 0.69624756\n",
      "Iteration 5, loss = 0.69016925\n",
      "Iteration 6, loss = 0.68494090\n",
      "Iteration 7, loss = 0.67667688\n",
      "Iteration 8, loss = 0.66605519\n",
      "Iteration 9, loss = 0.65784695\n",
      "Iteration 10, loss = 0.66255118\n",
      "Iteration 11, loss = 0.66646234\n",
      "Iteration 12, loss = 0.66303735\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6011315417256011"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpc_st = MLPClassifier(hidden_layer_sizes=(256, 128, 64, 32, 16, 8),\n",
    "                        alpha=0.15, max_iter=1000, batch_size=2000,\n",
    "                        verbose=True, learning_rate_init=0.01, tol=1e-5,\n",
    "                        learning_rate='adaptive')\n",
    "\n",
    "mlpc_st.fit(X_train_small, y_train_small_m)\n",
    "mlpc_st.score(X_test_small, y_test_small_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3302687411598303"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = mlpc_st.predict(X_test_small)\n",
    "sum(ypred) / len(ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 807, 1700,  321], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(ypred - y_test_small_m + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 807,    0,    0,    0,    0, 1700,    0,    0,    0,  321],\n",
       "       dtype=int64),\n",
       " array([0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8, 2. ]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(ypred - y_test_small_m + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
