{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import all the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import pickle, os, math\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Import the data first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There has been a huge mistake in the data generation. The mistake lies in the swap of x and y positions of the fighter. With the original data the accuracy stays constant around 50% in the balanced classes dataset, which shows that the data is not good enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10036, 20)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.path.join(os.curdir, 'Data', 'basic_data_short.pkl')\n",
    "with open(data_dir, 'rb') as in_file:\n",
    "    ot = pickle.load(in_file)\n",
    "data = ot['data']\n",
    "target = ot['target']\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = [None for i in range(data.shape[1])]\n",
    "for i in range(data.shape[1]):\n",
    "    sums[i] = np.sum(data.iloc[:, i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with help to [Thong Nguyen](https://medium.com/@thongonary/how-to-compute-f1-score-for-each-epoch-in-keras-a1acd17715a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_f1s = []\n",
    "        self.val_recalls = []\n",
    "        self.val_precisions = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = (np.asarray(self.model.predict(self.validation_data[0]))).round()\n",
    "        val_targ = self.validation_data[1]\n",
    "        _val_f1 = f1_score(val_targ, val_predict)\n",
    "        _val_recall = recall_score(val_targ, val_predict)\n",
    "        _val_precision = precision_score(val_targ, val_predict)\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        self.val_recalls.append(_val_recall)\n",
    "        self.val_precisions.append(_val_precision)\n",
    "        print(\"— val_f1: %f — val_precision: %f — val_recall %f\" % (_val_f1, _val_precision, _val_recall))\n",
    "        return\n",
    "\n",
    "metrics_usrdefined = Metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first raw data is unbalanced with classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, target, test_size=0.1, random_state=152)\n",
    "X_train.shape\n",
    "X_train_train, X_vali, y_train_train, y_vali = train_test_split(\n",
    "    X_train, y_train, test_size=0.3, random_state=152)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create balanced classes sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751\n",
      "751\n",
      "1502\n"
     ]
    }
   ],
   "source": [
    "index_0 = y_train.index[y_train[0] == 0].tolist()\n",
    "print(len(index_0))\n",
    "index_1 = y_train.index[y_train[0] != 0].tolist()\n",
    "index_1_comparable_to_0 = np.random.choice(index_1, math.floor(len(index_0) * 1))\n",
    "print(len(index_1_comparable_to_0))\n",
    "samples = np.concatenate([index_0, index_1_comparable_to_0])\n",
    "print(len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = data.iloc[samples, :]\n",
    "small_target = target.iloc[samples, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small, X_test_small, y_train_small, y_test_small = train_test_split(\n",
    "    small_data, small_target, test_size=0.3, random_state=152)\n",
    "X_train_train_small, X_vali_small, y_train_train_small, y_vali_small = train_test_split(\n",
    "    X_train_small, y_train_small, test_size=0.3, random_state=152)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Try running neural network first with raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=12, activation='relu', input_dim=20))\n",
    "model.add(Dense(units=6, activation='relu'))\n",
    "model.add(Dense(units=1, activation='linear'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6322 samples, validate on 2710 samples\n",
      "Epoch 1/10\n",
      "6322/6322 [==============================] - 0s 66us/step - loss: 31.3589 - acc: 0.1118 - val_loss: 4.1541 - val_acc: 0.0893\n",
      "Epoch 2/10\n",
      "6322/6322 [==============================] - 0s 9us/step - loss: 2.3754 - acc: 0.0944 - val_loss: 0.9969 - val_acc: 0.1218\n",
      "Epoch 3/10\n",
      "6322/6322 [==============================] - 0s 7us/step - loss: 0.6662 - acc: 0.5337 - val_loss: 0.2637 - val_acc: 0.8089\n",
      "Epoch 4/10\n",
      "6322/6322 [==============================] - 0s 9us/step - loss: 0.2400 - acc: 0.8307 - val_loss: 0.1578 - val_acc: 0.8387\n",
      "Epoch 5/10\n",
      "6322/6322 [==============================] - 0s 7us/step - loss: 0.1492 - acc: 0.8526 - val_loss: 0.1368 - val_acc: 0.8613\n",
      "Epoch 6/10\n",
      "6322/6322 [==============================] - 0s 7us/step - loss: 0.1331 - acc: 0.8591 - val_loss: 0.1282 - val_acc: 0.8631\n",
      "Epoch 7/10\n",
      "6322/6322 [==============================] - 0s 7us/step - loss: 0.1259 - acc: 0.8673 - val_loss: 0.1278 - val_acc: 0.8867\n",
      "Epoch 8/10\n",
      "6322/6322 [==============================] - 0s 9us/step - loss: 0.1218 - acc: 0.8738 - val_loss: 0.1222 - val_acc: 0.8749\n",
      "Epoch 9/10\n",
      "6322/6322 [==============================] - 0s 9us/step - loss: 0.1195 - acc: 0.8768 - val_loss: 0.1190 - val_acc: 0.8900\n",
      "Epoch 10/10\n",
      "6322/6322 [==============================] - 0s 8us/step - loss: 0.1176 - acc: 0.8853 - val_loss: 0.1172 - val_acc: 0.8930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bfe8ba8>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_train, y_train_train,\n",
    "          validation_data=(X_vali, y_vali), \n",
    "          epochs=10, batch_size=256, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1004/1004 [==============================] - 0s 14us/step\n",
      "[0.1111068560545188, 0.8964143397798576]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, y_test, batch_size=128)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The result is 98.4 accurate???\n",
    "\n",
    "It is a false hope. The model predicts everything to be one, and one takes up most of the data, so the result is really bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.895336379093003"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model.predict(X_test, batch_size=None, verbose=0)\n",
    "np.sum(y_predict) / len(y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Dealing with imbalanced classes\n",
    "\n",
    "try to make the balanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_small = Sequential()\n",
    "model_small.add(Dense(units=12, activation='relu', input_dim=20))\n",
    "model_small.add(Dense(units=12, activation='relu'))\n",
    "model_small.add(Dense(units=6, activation='relu'))\n",
    "model_small.add(Dense(units=1, activation='sigmoid'))\n",
    "model_small.compile(loss='mse',\n",
    "                    optimizer='rmsprop',\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 735 samples, validate on 316 samples\n",
      "Epoch 1/30\n",
      "735/735 [==============================] - 0s 516us/step - loss: 0.2782 - acc: 0.6163 - val_loss: 0.2484 - val_acc: 0.6487\n",
      "Epoch 2/30\n",
      "735/735 [==============================] - 0s 10us/step - loss: 0.2454 - acc: 0.6299 - val_loss: 0.2332 - val_acc: 0.6519\n",
      "Epoch 3/30\n",
      "735/735 [==============================] - 0s 10us/step - loss: 0.2409 - acc: 0.6327 - val_loss: 0.2429 - val_acc: 0.6551\n",
      "Epoch 4/30\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.2416 - acc: 0.6259 - val_loss: 0.2325 - val_acc: 0.6614\n",
      "Epoch 5/30\n",
      "735/735 [==============================] - 0s 12us/step - loss: 0.2398 - acc: 0.6422 - val_loss: 0.2310 - val_acc: 0.6709\n",
      "Epoch 6/30\n",
      "735/735 [==============================] - 0s 10us/step - loss: 0.2395 - acc: 0.6286 - val_loss: 0.2314 - val_acc: 0.6551\n",
      "Epoch 7/30\n",
      "735/735 [==============================] - 0s 12us/step - loss: 0.2403 - acc: 0.6218 - val_loss: 0.2385 - val_acc: 0.6519\n",
      "Epoch 8/30\n",
      "735/735 [==============================] - 0s 10us/step - loss: 0.2387 - acc: 0.6299 - val_loss: 0.2382 - val_acc: 0.6551\n",
      "Epoch 9/30\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.2355 - acc: 0.6272 - val_loss: 0.2312 - val_acc: 0.6234\n",
      "Epoch 10/30\n",
      "735/735 [==============================] - 0s 10us/step - loss: 0.2358 - acc: 0.6367 - val_loss: 0.2336 - val_acc: 0.6487\n",
      "Epoch 11/30\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.2345 - acc: 0.6177 - val_loss: 0.2353 - val_acc: 0.6582\n",
      "Epoch 12/30\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.2350 - acc: 0.6367 - val_loss: 0.2346 - val_acc: 0.6614\n",
      "Epoch 13/30\n",
      "735/735 [==============================] - 0s 12us/step - loss: 0.2342 - acc: 0.6354 - val_loss: 0.2298 - val_acc: 0.6329\n",
      "Epoch 14/30\n",
      "735/735 [==============================] - 0s 14us/step - loss: 0.2335 - acc: 0.6449 - val_loss: 0.2279 - val_acc: 0.6456\n",
      "Epoch 15/30\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.2318 - acc: 0.6381 - val_loss: 0.2284 - val_acc: 0.6266\n",
      "Epoch 16/30\n",
      "735/735 [==============================] - 0s 8us/step - loss: 0.2343 - acc: 0.6327 - val_loss: 0.2278 - val_acc: 0.6551\n",
      "Epoch 17/30\n",
      "735/735 [==============================] - 0s 10us/step - loss: 0.2315 - acc: 0.6476 - val_loss: 0.2263 - val_acc: 0.6456\n",
      "Epoch 18/30\n",
      "735/735 [==============================] - 0s 10us/step - loss: 0.2310 - acc: 0.6449 - val_loss: 0.2267 - val_acc: 0.6614\n",
      "Epoch 19/30\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.2299 - acc: 0.6422 - val_loss: 0.2299 - val_acc: 0.6519\n",
      "Epoch 20/30\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.2290 - acc: 0.6408 - val_loss: 0.2274 - val_acc: 0.6392\n",
      "Epoch 21/30\n",
      "735/735 [==============================] - 0s 22us/step - loss: 0.2280 - acc: 0.6490 - val_loss: 0.2256 - val_acc: 0.6392\n",
      "Epoch 22/30\n",
      "735/735 [==============================] - 0s 10us/step - loss: 0.2304 - acc: 0.6327 - val_loss: 0.2308 - val_acc: 0.6582\n",
      "Epoch 23/30\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.2315 - acc: 0.6367 - val_loss: 0.2263 - val_acc: 0.6582\n",
      "Epoch 24/30\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.2292 - acc: 0.6231 - val_loss: 0.2247 - val_acc: 0.6551\n",
      "Epoch 25/30\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.2273 - acc: 0.6381 - val_loss: 0.2244 - val_acc: 0.6297\n",
      "Epoch 26/30\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.2272 - acc: 0.6395 - val_loss: 0.2275 - val_acc: 0.6614\n",
      "Epoch 27/30\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.2282 - acc: 0.6272 - val_loss: 0.2287 - val_acc: 0.6582\n",
      "Epoch 28/30\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.2278 - acc: 0.6367 - val_loss: 0.2256 - val_acc: 0.6456\n",
      "Epoch 29/30\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.2263 - acc: 0.6381 - val_loss: 0.2261 - val_acc: 0.6424\n",
      "Epoch 30/30\n",
      "735/735 [==============================] - 0s 14us/step - loss: 0.2244 - acc: 0.6476 - val_loss: 0.2264 - val_acc: 0.6329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bfe8a58>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_small.fit(X_train_train_small, y_train_train_small,\n",
    "          validation_data=(X_vali_small, y_vali_small), \n",
    "          epochs=30, batch_size=256, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451/451 [==============================] - 0s 22us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24085947527589396, 0.6141906911940902]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics_small = model_small.evaluate(X_test_small, y_test_small, batch_size=128)\n",
    "loss_and_metrics_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_small = model_small.predict(X_test_small, batch_size=None, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44867575],\n",
       "       [0.68468565],\n",
       "       [0.45711303],\n",
       "       [0.7691097 ],\n",
       "       [0.9617938 ],\n",
       "       [0.50410706],\n",
       "       [0.67709327],\n",
       "       [0.2604741 ],\n",
       "       [0.32972294],\n",
       "       [0.81773615],\n",
       "       [0.4209635 ],\n",
       "       [0.6498014 ],\n",
       "       [0.7183083 ],\n",
       "       [0.664088  ],\n",
       "       [0.72290903],\n",
       "       [0.2890113 ],\n",
       "       [0.6830206 ],\n",
       "       [0.27220523],\n",
       "       [0.7227996 ],\n",
       "       [0.5953881 ],\n",
       "       [0.68468565],\n",
       "       [0.29619032],\n",
       "       [0.62030965],\n",
       "       [0.7224319 ],\n",
       "       [0.6261387 ],\n",
       "       [0.30462673],\n",
       "       [0.4693328 ],\n",
       "       [0.6802505 ],\n",
       "       [0.32444766],\n",
       "       [0.03274462],\n",
       "       [0.33386666],\n",
       "       [0.43028706],\n",
       "       [0.67709327],\n",
       "       [0.01346624],\n",
       "       [0.6916057 ],\n",
       "       [0.5148759 ],\n",
       "       [0.22392902],\n",
       "       [0.32607248],\n",
       "       [0.6432943 ],\n",
       "       [0.40073988],\n",
       "       [0.68262357],\n",
       "       [0.52356106],\n",
       "       [0.94577885],\n",
       "       [0.5201209 ],\n",
       "       [0.3330629 ],\n",
       "       [0.68849635],\n",
       "       [0.49028417],\n",
       "       [0.27951288],\n",
       "       [0.519216  ],\n",
       "       [0.9159093 ],\n",
       "       [0.52432483],\n",
       "       [0.69143456],\n",
       "       [0.23626599],\n",
       "       [0.6272575 ],\n",
       "       [0.622061  ],\n",
       "       [0.6709535 ],\n",
       "       [0.5641405 ],\n",
       "       [0.367831  ],\n",
       "       [0.5739801 ],\n",
       "       [0.72290903],\n",
       "       [0.7117512 ],\n",
       "       [0.315497  ],\n",
       "       [0.54765207],\n",
       "       [0.5092949 ],\n",
       "       [0.57236403],\n",
       "       [0.54786074],\n",
       "       [0.49652973],\n",
       "       [0.2699107 ],\n",
       "       [0.17499894],\n",
       "       [0.47592556],\n",
       "       [0.80186784],\n",
       "       [0.46118447],\n",
       "       [0.9662473 ],\n",
       "       [0.68262357],\n",
       "       [0.7245927 ],\n",
       "       [0.920226  ],\n",
       "       [0.39059964],\n",
       "       [0.68888927],\n",
       "       [0.7791338 ],\n",
       "       [0.41954544],\n",
       "       [0.67669225],\n",
       "       [0.4922547 ],\n",
       "       [0.6340762 ],\n",
       "       [0.52490467],\n",
       "       [0.43232933],\n",
       "       [0.40441155],\n",
       "       [0.6916057 ],\n",
       "       [0.8073385 ],\n",
       "       [0.1264154 ],\n",
       "       [0.29814184],\n",
       "       [0.6637767 ],\n",
       "       [0.7143508 ],\n",
       "       [0.701674  ],\n",
       "       [0.5020253 ],\n",
       "       [0.0217841 ],\n",
       "       [0.693957  ],\n",
       "       [0.26648748],\n",
       "       [0.5498353 ],\n",
       "       [0.90276265],\n",
       "       [0.6114656 ],\n",
       "       [0.65692276],\n",
       "       [0.29303735],\n",
       "       [0.6884824 ],\n",
       "       [0.5943291 ],\n",
       "       [0.6650674 ],\n",
       "       [0.82727385],\n",
       "       [0.44918618],\n",
       "       [0.4213169 ],\n",
       "       [0.7627439 ],\n",
       "       [0.46469206],\n",
       "       [0.3127318 ],\n",
       "       [0.46211395],\n",
       "       [0.5183671 ],\n",
       "       [0.45814458],\n",
       "       [0.5378108 ],\n",
       "       [0.47796652],\n",
       "       [0.40807253],\n",
       "       [0.7227996 ],\n",
       "       [0.3032236 ],\n",
       "       [0.5739801 ],\n",
       "       [0.28679788],\n",
       "       [0.51635945],\n",
       "       [0.6213443 ],\n",
       "       [0.4479302 ],\n",
       "       [0.41418758],\n",
       "       [0.6778574 ],\n",
       "       [0.765342  ],\n",
       "       [0.7335825 ],\n",
       "       [0.50434387],\n",
       "       [0.60626006],\n",
       "       [0.7598127 ],\n",
       "       [0.6456186 ],\n",
       "       [0.56780916],\n",
       "       [0.72909606],\n",
       "       [0.3346656 ],\n",
       "       [0.16273671],\n",
       "       [0.70574945],\n",
       "       [0.45931485],\n",
       "       [0.6554173 ],\n",
       "       [0.5851879 ],\n",
       "       [0.6161104 ],\n",
       "       [0.6456003 ],\n",
       "       [0.420952  ],\n",
       "       [0.53081626],\n",
       "       [0.6518266 ],\n",
       "       [0.7627439 ],\n",
       "       [0.67669225],\n",
       "       [0.56111175],\n",
       "       [0.42868602],\n",
       "       [0.11424062],\n",
       "       [0.53526485],\n",
       "       [0.17479894],\n",
       "       [0.6277324 ],\n",
       "       [0.40554127],\n",
       "       [0.74374574],\n",
       "       [0.60626006],\n",
       "       [0.63916284],\n",
       "       [0.15347216],\n",
       "       [0.2954263 ],\n",
       "       [0.5995512 ],\n",
       "       [0.16492936],\n",
       "       [0.6761315 ],\n",
       "       [0.42864132],\n",
       "       [0.67390645],\n",
       "       [0.5995512 ],\n",
       "       [0.54850054],\n",
       "       [0.69987935],\n",
       "       [0.74409497],\n",
       "       [0.21577021],\n",
       "       [0.33092868],\n",
       "       [0.17891484],\n",
       "       [0.6583167 ],\n",
       "       [0.6179177 ],\n",
       "       [0.30293608],\n",
       "       [0.63366663],\n",
       "       [0.6261387 ],\n",
       "       [0.664088  ],\n",
       "       [0.72290903],\n",
       "       [0.4940241 ],\n",
       "       [0.619556  ],\n",
       "       [0.37067682],\n",
       "       [0.3812542 ],\n",
       "       [0.9728391 ],\n",
       "       [0.5995512 ],\n",
       "       [0.6059278 ],\n",
       "       [0.36920235],\n",
       "       [0.31090963],\n",
       "       [0.5860231 ],\n",
       "       [0.6179177 ],\n",
       "       [0.71987736],\n",
       "       [0.5814056 ],\n",
       "       [0.6403738 ],\n",
       "       [0.11745831],\n",
       "       [0.2519812 ],\n",
       "       [0.5736374 ],\n",
       "       [0.72290903],\n",
       "       [0.43899632],\n",
       "       [0.5201651 ],\n",
       "       [0.5216407 ],\n",
       "       [0.7442951 ],\n",
       "       [0.5566387 ],\n",
       "       [0.7275004 ],\n",
       "       [0.62030965],\n",
       "       [0.06216511],\n",
       "       [0.7548057 ],\n",
       "       [0.90649307],\n",
       "       [0.72290903],\n",
       "       [0.921698  ],\n",
       "       [0.7492479 ],\n",
       "       [0.5641405 ],\n",
       "       [0.71726054],\n",
       "       [0.31121445],\n",
       "       [0.15025106],\n",
       "       [0.56780916],\n",
       "       [0.7836169 ],\n",
       "       [0.22098511],\n",
       "       [0.6340762 ],\n",
       "       [0.3449334 ],\n",
       "       [0.72848696],\n",
       "       [0.5928047 ],\n",
       "       [0.27772072],\n",
       "       [0.7164159 ],\n",
       "       [0.6456003 ],\n",
       "       [0.47053546],\n",
       "       [0.3289153 ],\n",
       "       [0.8167683 ],\n",
       "       [0.29968137],\n",
       "       [0.74972904],\n",
       "       [0.69994175],\n",
       "       [0.52095777],\n",
       "       [0.619556  ],\n",
       "       [0.44205645],\n",
       "       [0.51885563],\n",
       "       [0.6213443 ],\n",
       "       [0.6589718 ],\n",
       "       [0.32673413],\n",
       "       [0.69143456],\n",
       "       [0.32200354],\n",
       "       [0.53950244],\n",
       "       [0.3899477 ],\n",
       "       [0.51748294],\n",
       "       [0.24826548],\n",
       "       [0.5158531 ],\n",
       "       [0.6019336 ],\n",
       "       [0.664088  ],\n",
       "       [0.2299566 ],\n",
       "       [0.4239754 ],\n",
       "       [0.56666964],\n",
       "       [0.54858667],\n",
       "       [0.69417816],\n",
       "       [0.6973859 ],\n",
       "       [0.6403738 ],\n",
       "       [0.4929579 ],\n",
       "       [0.47565648],\n",
       "       [0.87380147],\n",
       "       [0.6462481 ],\n",
       "       [0.4323705 ],\n",
       "       [0.5928047 ],\n",
       "       [0.5166543 ],\n",
       "       [0.63701904],\n",
       "       [0.6267048 ],\n",
       "       [0.7278616 ],\n",
       "       [0.67986476],\n",
       "       [0.37629977],\n",
       "       [0.5943291 ],\n",
       "       [0.6650674 ],\n",
       "       [0.3341377 ],\n",
       "       [0.4558343 ],\n",
       "       [0.5012227 ],\n",
       "       [0.54205686],\n",
       "       [0.56839263],\n",
       "       [0.43529886],\n",
       "       [0.6579837 ],\n",
       "       [0.41229308],\n",
       "       [0.5332064 ],\n",
       "       [0.70875764],\n",
       "       [0.72848696],\n",
       "       [0.53156596],\n",
       "       [0.35015658],\n",
       "       [0.63916284],\n",
       "       [0.68849635],\n",
       "       [0.4816813 ],\n",
       "       [0.487451  ],\n",
       "       [0.5408949 ],\n",
       "       [0.70044506],\n",
       "       [0.6432943 ],\n",
       "       [0.32925773],\n",
       "       [0.36137474],\n",
       "       [0.68460107],\n",
       "       [0.5270709 ],\n",
       "       [0.6456003 ],\n",
       "       [0.3583514 ],\n",
       "       [0.62760586],\n",
       "       [0.3948791 ],\n",
       "       [0.61387235],\n",
       "       [0.3565585 ],\n",
       "       [0.34473515],\n",
       "       [0.6213443 ],\n",
       "       [0.741317  ],\n",
       "       [0.21142864],\n",
       "       [0.32865006],\n",
       "       [0.9506326 ],\n",
       "       [0.7696151 ],\n",
       "       [0.70044506],\n",
       "       [0.5138492 ],\n",
       "       [0.33507997],\n",
       "       [0.68849635],\n",
       "       [0.369847  ],\n",
       "       [0.6650674 ],\n",
       "       [0.6711084 ],\n",
       "       [0.9479721 ],\n",
       "       [0.52340573],\n",
       "       [0.29744577],\n",
       "       [0.6073953 ],\n",
       "       [0.67390645],\n",
       "       [0.6981029 ],\n",
       "       [0.36828396],\n",
       "       [0.68206865],\n",
       "       [0.7598127 ],\n",
       "       [0.8127104 ],\n",
       "       [0.9242668 ],\n",
       "       [0.69469774],\n",
       "       [0.44884193],\n",
       "       [0.5071522 ],\n",
       "       [0.46074897],\n",
       "       [0.38504648],\n",
       "       [0.729779  ],\n",
       "       [0.52548003],\n",
       "       [0.67390645],\n",
       "       [0.68468565],\n",
       "       [0.31677818],\n",
       "       [0.57112104],\n",
       "       [0.57236403],\n",
       "       [0.11706465],\n",
       "       [0.38300806],\n",
       "       [0.39370802],\n",
       "       [0.7791338 ],\n",
       "       [0.74972904],\n",
       "       [0.68888927],\n",
       "       [0.63701904],\n",
       "       [0.39033318],\n",
       "       [0.46831757],\n",
       "       [0.6084429 ],\n",
       "       [0.5860231 ],\n",
       "       [0.5349141 ],\n",
       "       [0.6981029 ],\n",
       "       [0.8301087 ],\n",
       "       [0.4895513 ],\n",
       "       [0.41443086],\n",
       "       [0.7325052 ],\n",
       "       [0.70574945],\n",
       "       [0.36406434],\n",
       "       [0.9384031 ],\n",
       "       [0.39786625],\n",
       "       [0.71084857],\n",
       "       [0.71726054],\n",
       "       [0.6589718 ],\n",
       "       [0.5270709 ],\n",
       "       [0.62030965],\n",
       "       [0.6778908 ],\n",
       "       [0.6179177 ],\n",
       "       [0.3463456 ],\n",
       "       [0.18450832],\n",
       "       [0.69430894],\n",
       "       [0.5336473 ],\n",
       "       [0.5521244 ],\n",
       "       [0.4579075 ],\n",
       "       [0.7372121 ],\n",
       "       [0.664088  ],\n",
       "       [0.741317  ],\n",
       "       [0.5860231 ],\n",
       "       [0.3289703 ],\n",
       "       [0.34974068],\n",
       "       [0.70468843],\n",
       "       [0.48148865],\n",
       "       [0.49770308],\n",
       "       [0.30206835],\n",
       "       [0.71786964],\n",
       "       [0.68849635],\n",
       "       [0.7385191 ],\n",
       "       [0.817327  ],\n",
       "       [0.33402213],\n",
       "       [0.59844506],\n",
       "       [0.97926426],\n",
       "       [0.6019336 ],\n",
       "       [0.70574945],\n",
       "       [0.68206865],\n",
       "       [0.39541882],\n",
       "       [0.6709535 ],\n",
       "       [0.6277324 ],\n",
       "       [0.612929  ],\n",
       "       [0.28916445],\n",
       "       [0.6857649 ],\n",
       "       [0.612929  ],\n",
       "       [0.65109277],\n",
       "       [0.6927319 ],\n",
       "       [0.5928047 ],\n",
       "       [0.937811  ],\n",
       "       [0.65692276],\n",
       "       [0.62804323],\n",
       "       [0.3186052 ],\n",
       "       [0.4032374 ],\n",
       "       [0.57236403],\n",
       "       [0.50582373],\n",
       "       [0.14666858],\n",
       "       [0.30032527],\n",
       "       [0.4567427 ],\n",
       "       [0.6456186 ],\n",
       "       [0.56501484],\n",
       "       [0.77440995],\n",
       "       [0.36504805],\n",
       "       [0.6973859 ],\n",
       "       [0.29297006],\n",
       "       [0.65692276],\n",
       "       [0.1322346 ],\n",
       "       [0.65282327],\n",
       "       [0.56111175],\n",
       "       [0.21766257],\n",
       "       [0.6707037 ],\n",
       "       [0.3648935 ],\n",
       "       [0.5411217 ],\n",
       "       [0.619556  ],\n",
       "       [0.4914811 ],\n",
       "       [0.21603331],\n",
       "       [0.3796057 ],\n",
       "       [0.763429  ],\n",
       "       [0.6579837 ],\n",
       "       [0.6306964 ],\n",
       "       [0.38725954],\n",
       "       [0.6330559 ],\n",
       "       [0.6084429 ],\n",
       "       [0.00153124],\n",
       "       [0.28975838],\n",
       "       [0.2981693 ],\n",
       "       [0.19966847],\n",
       "       [0.7543314 ],\n",
       "       [0.8427974 ],\n",
       "       [0.4924493 ],\n",
       "       [0.5340103 ],\n",
       "       [0.287005  ],\n",
       "       [0.36406434],\n",
       "       [0.6711084 ],\n",
       "       [0.25255808],\n",
       "       [0.6267048 ],\n",
       "       [0.5024596 ],\n",
       "       [0.6213443 ],\n",
       "       [0.6242631 ],\n",
       "       [0.42868602],\n",
       "       [0.38047373],\n",
       "       [0.32693672],\n",
       "       [0.68849623]], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. test the neural network with a small dataset from sklearn\n",
    "\n",
    "using the cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "res = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = res['data']\n",
    "y = res['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ctr, X_cte, y_ctr, y_cte = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cancer = Sequential()\n",
    "model_cancer.add(Dense(units=12, activation='relu', input_dim=30))\n",
    "model_cancer.add(Dense(units=12, activation='relu'))\n",
    "model_cancer.add(Dense(units=6, activation='relu'))\n",
    "model_cancer.add(Dense(units=1, activation='sigmoid'))\n",
    "model_cancer.compile(loss='mse',\n",
    "                    optimizer='rmsprop',\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.5930 - acc: 0.4070\n",
      "Epoch 2/20\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.5929 - acc: 0.4070\n",
      "Epoch 3/20\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.5911 - acc: 0.4070\n",
      "Epoch 4/20\n",
      "398/398 [==============================] - 0s 15us/step - loss: 0.4944 - acc: 0.4070\n",
      "Epoch 5/20\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.1831 - acc: 0.8543\n",
      "Epoch 6/20\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.1719 - acc: 0.8668\n",
      "Epoch 7/20\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.1722 - acc: 0.8719\n",
      "Epoch 8/20\n",
      "398/398 [==============================] - 0s 25us/step - loss: 0.1734 - acc: 0.8920\n",
      "Epoch 9/20\n",
      "398/398 [==============================] - 0s 15us/step - loss: 0.1882 - acc: 0.8593\n",
      "Epoch 10/20\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.1744 - acc: 0.8643\n",
      "Epoch 11/20\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.1788 - acc: 0.8945\n",
      "Epoch 12/20\n",
      "398/398 [==============================] - 0s 20us/step - loss: 0.1692 - acc: 0.8744\n",
      "Epoch 13/20\n",
      "398/398 [==============================] - 0s 18us/step - loss: 0.1667 - acc: 0.9045\n",
      "Epoch 14/20\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.1660 - acc: 0.9020\n",
      "Epoch 15/20\n",
      "398/398 [==============================] - 0s 30us/step - loss: 0.1653 - acc: 0.9095\n",
      "Epoch 16/20\n",
      "398/398 [==============================] - 0s 28us/step - loss: 0.1666 - acc: 0.8920\n",
      "Epoch 17/20\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.1697 - acc: 0.8894\n",
      "Epoch 18/20\n",
      "398/398 [==============================] - 0s 55us/step - loss: 0.1650 - acc: 0.8945\n",
      "Epoch 19/20\n",
      "398/398 [==============================] - 0s 28us/step - loss: 0.1745 - acc: 0.8568\n",
      "Epoch 20/20\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.1693 - acc: 0.8744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c391b38>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cancer.fit(X_ctr, y_ctr, \n",
    "          epochs=20, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 0s 971us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.20131064872992666, 0.8947368375739159]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics = model_cancer.evaluate(X_cte, y_cte, batch_size=128)\n",
    "y_predict_cancer = model_cancer.predict(X_cte, batch_size=None, verbose=0)\n",
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It can be seen that the neural network written in keras works fine.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. test with a small mlp from scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpc = MLPClassifier(hidden_layer_sizes=(100, 100, 100), alpha=0.001, max_iter=1000, verbose=True, learning_rate_init=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 8.42484907\n",
      "Iteration 2, loss = 13.65406408\n",
      "Iteration 3, loss = 5.54811978\n",
      "Iteration 4, loss = 9.37276279\n",
      "Iteration 5, loss = 8.37660426\n",
      "Iteration 6, loss = 13.55436156\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 100, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.01, max_iter=1000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpc.fit(X_ctr, y_ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29239766081871343"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpc.score(X_cte, y_cte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.  test with the data that I have using sklearn MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpc_1 = MLPClassifier(hidden_layer_sizes=(200, 100, 100, 100),\n",
    "                       alpha=0.05, max_iter=1000, \n",
    "                       verbose=True, learning_rate_init=0.02, tol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.validation import column_or_1d\n",
    "y_train_small_m = np.ravel(y_train_small)\n",
    "y_test_small_m = np.ravel(y_test_small)\n",
    "len(y_train_small_m)\n",
    "y_train_m = np.ravel(y_train)\n",
    "y_test_m = np.ravel(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small_less_1 = X_train_small.iloc[:, 3:13]\n",
    "X_train_small_less_2 = X_train_small.iloc[:, 16:]\n",
    "X_train_small_less = pd.concat([X_train_small_less_1, X_train_small_less_2], axis=1)\n",
    "\n",
    "X_test_small_less_1 = X_test_small.iloc[:, 3:13]\n",
    "X_test_small_less_2 = X_test_small.iloc[:, 16:]\n",
    "X_test_small_less = pd.concat([X_test_small_less_1, X_test_small_less_2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>-19</td>\n",
       "      <td>-19</td>\n",
       "      <td>-19</td>\n",
       "      <td>-19</td>\n",
       "      <td>-19</td>\n",
       "      <td>-19</td>\n",
       "      <td>-19</td>\n",
       "      <td>-19</td>\n",
       "      <td>0</td>\n",
       "      <td>-19</td>\n",
       "      <td>-19</td>\n",
       "      <td>-19</td>\n",
       "      <td>-19</td>\n",
       "      <td>-19</td>\n",
       "      <td>-19</td>\n",
       "      <td>-19</td>\n",
       "      <td>-19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>-30</td>\n",
       "      <td>-30</td>\n",
       "      <td>-30</td>\n",
       "      <td>-30</td>\n",
       "      <td>-30</td>\n",
       "      <td>-30</td>\n",
       "      <td>-4</td>\n",
       "      <td>-30</td>\n",
       "      <td>0</td>\n",
       "      <td>-30</td>\n",
       "      <td>-30</td>\n",
       "      <td>-30</td>\n",
       "      <td>-30</td>\n",
       "      <td>-30</td>\n",
       "      <td>-30</td>\n",
       "      <td>-30</td>\n",
       "      <td>-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5926</th>\n",
       "      <td>-22</td>\n",
       "      <td>-22</td>\n",
       "      <td>-22</td>\n",
       "      <td>-11</td>\n",
       "      <td>-22</td>\n",
       "      <td>-22</td>\n",
       "      <td>-22</td>\n",
       "      <td>-22</td>\n",
       "      <td>0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-15</td>\n",
       "      <td>-22</td>\n",
       "      <td>-22</td>\n",
       "      <td>-22</td>\n",
       "      <td>-22</td>\n",
       "      <td>-22</td>\n",
       "      <td>-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>-14</td>\n",
       "      <td>-14</td>\n",
       "      <td>-14</td>\n",
       "      <td>-14</td>\n",
       "      <td>-14</td>\n",
       "      <td>-14</td>\n",
       "      <td>-14</td>\n",
       "      <td>-14</td>\n",
       "      <td>0</td>\n",
       "      <td>-14</td>\n",
       "      <td>-14</td>\n",
       "      <td>-14</td>\n",
       "      <td>-14</td>\n",
       "      <td>-14</td>\n",
       "      <td>-14</td>\n",
       "      <td>-14</td>\n",
       "      <td>-14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>-28</td>\n",
       "      <td>-28</td>\n",
       "      <td>-28</td>\n",
       "      <td>-28</td>\n",
       "      <td>-28</td>\n",
       "      <td>-28</td>\n",
       "      <td>-28</td>\n",
       "      <td>-28</td>\n",
       "      <td>0</td>\n",
       "      <td>-28</td>\n",
       "      <td>-28</td>\n",
       "      <td>-28</td>\n",
       "      <td>-28</td>\n",
       "      <td>-28</td>\n",
       "      <td>-28</td>\n",
       "      <td>-28</td>\n",
       "      <td>-28</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17  \\\n",
       "9089 -19 -19 -19 -19 -19 -19 -19 -19   0 -19 -19 -19 -19 -19 -19 -19 -19   0   \n",
       "717  -30 -30 -30 -30 -30 -30  -4 -30   0 -30 -30 -30 -30 -30 -30 -30 -30   0   \n",
       "5926 -22 -22 -22 -11 -22 -22 -22 -22   0 -22 -15 -22 -22 -22 -22 -22 -22   0   \n",
       "1587 -14 -14 -14 -14 -14 -14 -14 -14   0 -14 -14 -14 -14 -14 -14 -14 -14   0   \n",
       "2492 -28 -28 -28 -28 -28 -28 -28 -28   0 -28 -28 -28 -28 -28 -28 -28 -28   0   \n",
       "\n",
       "      18  19  \n",
       "9089   0  -1  \n",
       "717    0  -1  \n",
       "5926   0  -1  \n",
       "1587   1   0  \n",
       "2492  -1   0  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 5.17459388\n",
      "Iteration 2, loss = 0.77276659\n",
      "Iteration 3, loss = 0.77883965\n",
      "Iteration 4, loss = 0.78696057\n",
      "Iteration 5, loss = 0.77285415\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(200, 100, 100, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.02, max_iter=1000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpc_1.fit(X_train_small, y_train_small_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4722838137472284"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpc_1.score(X_test_small, y_test_small_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_111 = mlpc_1.predict(X_test_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5898004434589801"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_111) / len(test_111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is still very low, so it's not the problem of the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write the input and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200036, 24)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.path.join(os.curdir, 'Data', 'basic_data_pics.pkl')\n",
    "with open(data_dir, 'rb') as in_file:\n",
    "    ot = pickle.load(in_file)\n",
    "data_pics = ot['data']\n",
    "target_pics = ot['target']\n",
    "data_pics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15061\n",
      "15061\n",
      "30122\n",
      "Iteration 1, loss = 1.62310334\n",
      "Iteration 2, loss = 0.81915544\n",
      "Iteration 3, loss = 0.71384423\n",
      "Iteration 4, loss = 0.68024405\n",
      "Iteration 5, loss = 0.66975287\n",
      "Iteration 6, loss = 0.65317108\n",
      "Iteration 7, loss = 0.63248675\n",
      "Iteration 8, loss = 0.61385616\n",
      "Iteration 9, loss = 0.57677913\n",
      "Iteration 10, loss = 0.58830787\n",
      "Iteration 11, loss = 0.56820350\n",
      "Iteration 12, loss = 0.53298257\n",
      "Iteration 13, loss = 0.50769968\n",
      "Iteration 14, loss = 0.49246782\n",
      "Iteration 15, loss = 0.47991118\n",
      "Iteration 16, loss = 0.46620214\n",
      "Iteration 17, loss = 0.45355448\n",
      "Iteration 18, loss = 0.44869671\n",
      "Iteration 19, loss = 0.42900878\n",
      "Iteration 20, loss = 0.41890564\n",
      "Iteration 21, loss = 0.41205634\n",
      "Iteration 22, loss = 0.40913743\n",
      "Iteration 23, loss = 0.39784794\n",
      "Iteration 24, loss = 0.38503140\n",
      "Iteration 25, loss = 0.37611784\n",
      "Iteration 26, loss = 0.36697884\n",
      "Iteration 27, loss = 0.36234619\n",
      "Iteration 28, loss = 0.36068061\n",
      "Iteration 29, loss = 0.35368966\n",
      "Iteration 30, loss = 0.34553209\n",
      "Iteration 31, loss = 0.36140740\n",
      "Iteration 32, loss = 0.38846308\n",
      "Iteration 33, loss = 0.36344844\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8558149828482904"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_pics, target_pics, test_size=0.1, random_state=152)\n",
    "X_train.shape\n",
    "X_train_train, X_vali, y_train_train, y_vali = train_test_split(\n",
    "    X_train, y_train, test_size=0.3, random_state=152)\n",
    "\n",
    "index_0 = y_train.index[y_train[0] == 0].tolist()\n",
    "print(len(index_0))\n",
    "index_1 = y_train.index[y_train[0] != 0].tolist()\n",
    "index_1_comparable_to_0 = np.random.choice(index_1, math.floor(len(index_0) * 1))\n",
    "print(len(index_1_comparable_to_0))\n",
    "samples = np.concatenate([index_0, index_1_comparable_to_0])\n",
    "print(len(samples))\n",
    "\n",
    "small_data = data_pics.iloc[samples, :]\n",
    "small_target = target_pics.iloc[samples, :]\n",
    "\n",
    "\n",
    "X_train_small, X_test_small, y_train_small, y_test_small = train_test_split(\n",
    "    small_data, small_target, test_size=0.3, random_state=152)\n",
    "X_train_train_small, X_vali_small, y_train_train_small, y_vali_small = train_test_split(\n",
    "    X_train_small, y_train_small, test_size=0.3, random_state=152)\n",
    "\n",
    "mlpc_1 = MLPClassifier(hidden_layer_sizes=(50, 20),\n",
    "                       alpha=0.15, max_iter=1000, batch_size=5000,\n",
    "                       verbose=True, learning_rate_init=0.01, tol=1e-5,\n",
    "                       learning_rate='adaptive' )\n",
    "from sklearn.utils.validation import column_or_1d\n",
    "y_train_small_m = np.ravel(y_train_small)\n",
    "y_test_small_m = np.ravel(y_test_small)\n",
    "len(y_train_small_m)\n",
    "y_train_m = np.ravel(y_train)\n",
    "y_test_m = np.ravel(y_test)\n",
    "\n",
    "\n",
    "X_train_small_less_1 = X_train_small.iloc[:, 3:13]\n",
    "X_train_small_less_2 = X_train_small.iloc[:, 16:]\n",
    "X_train_small_less = pd.concat([X_train_small_less_1, X_train_small_less_2], axis=1)\n",
    "\n",
    "X_test_small_less_1 = X_test_small.iloc[:, 3:13]\n",
    "X_test_small_less_2 = X_test_small.iloc[:, 16:]\n",
    "X_test_small_less = pd.concat([X_test_small_less_1, X_test_small_less_2], axis=1)\n",
    "\n",
    "\n",
    "mlpc_1.fit(X_train_small, y_train_small_m)\n",
    "\n",
    "mlpc_1.score(X_test_small, y_test_small_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_111 = mlpc_1.predict(X_test_small)\n",
    "test_111[1:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9136672665466906\n",
      "0.5047028881265907\n"
     ]
    }
   ],
   "source": [
    "print(sum(y_test_m) / len(y_test_m))\n",
    "print(sum(y_test_small_m) / len(y_test_small_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.958258348330334"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpc_1.score(X_test, y_test_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(mlpc_1, 'model1.joblib')\n",
    "mlpc_loaded = joblib.load('model1.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9399136881708532"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf_1 = SVC(C=10.0, gamma='auto', verbose=True)\n",
    "clf_1.fit(X_train_small, y_train_small_m)\n",
    "clf_1.score(X_test_small, y_test_small_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.94366999, 0.93767786, 0.9359704 , 0.93312464, 0.93938532,\n",
       "       0.93881616])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(clf_1, X_train_small, y_train_small_m, cv=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.88284952\n",
      "Iteration 2, loss = 0.66759262\n",
      "Iteration 3, loss = 0.62895208\n",
      "Iteration 4, loss = 0.61218429\n",
      "Iteration 5, loss = 0.57720381\n",
      "Iteration 6, loss = 0.54981722\n",
      "Iteration 7, loss = 0.51765892\n",
      "Iteration 8, loss = 0.50013930\n",
      "Iteration 9, loss = 0.48909796\n",
      "Iteration 10, loss = 0.47935739\n",
      "Iteration 11, loss = 0.45658515\n",
      "Iteration 12, loss = 0.45089568\n",
      "Iteration 13, loss = 0.45674121\n",
      "Iteration 14, loss = 0.43945241\n",
      "Iteration 15, loss = 0.42206926\n",
      "Iteration 16, loss = 0.41105896\n",
      "Iteration 17, loss = 0.39946057\n",
      "Iteration 18, loss = 0.39004794\n",
      "Iteration 19, loss = 0.37715327\n",
      "Iteration 20, loss = 0.38680214\n",
      "Iteration 21, loss = 0.39684353\n",
      "Iteration 22, loss = 0.38501631\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.64552734\n",
      "Iteration 2, loss = 0.71926146\n",
      "Iteration 3, loss = 0.70405667\n",
      "Iteration 4, loss = 0.58109583\n",
      "Iteration 5, loss = 0.52792530\n",
      "Iteration 6, loss = 0.51817925\n",
      "Iteration 7, loss = 0.47651894\n",
      "Iteration 8, loss = 0.45765038\n",
      "Iteration 9, loss = 0.43558730\n",
      "Iteration 10, loss = 0.40675339\n",
      "Iteration 11, loss = 0.38886205\n",
      "Iteration 12, loss = 0.38492915\n",
      "Iteration 13, loss = 0.39351140\n",
      "Iteration 14, loss = 0.37639221\n",
      "Iteration 15, loss = 0.36054143\n",
      "Iteration 16, loss = 0.35549829\n",
      "Iteration 17, loss = 0.34862443\n",
      "Iteration 18, loss = 0.33884346\n",
      "Iteration 19, loss = 0.32957949\n",
      "Iteration 20, loss = 0.33085336\n",
      "Iteration 21, loss = 0.32807607\n",
      "Iteration 22, loss = 0.32997248\n",
      "Iteration 23, loss = 0.32456260\n",
      "Iteration 24, loss = 0.30887301\n",
      "Iteration 25, loss = 0.30505758\n",
      "Iteration 26, loss = 0.30174429\n",
      "Iteration 27, loss = 0.29808045\n",
      "Iteration 28, loss = 0.29979687\n",
      "Iteration 29, loss = 0.30218907\n",
      "Iteration 30, loss = 0.29928528\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.33549508\n",
      "Iteration 2, loss = 0.66994095\n",
      "Iteration 3, loss = 0.63123772\n",
      "Iteration 4, loss = 0.59644540\n",
      "Iteration 5, loss = 0.56558722\n",
      "Iteration 6, loss = 0.53934228\n",
      "Iteration 7, loss = 0.52787955\n",
      "Iteration 8, loss = 0.50444826\n",
      "Iteration 9, loss = 0.50225374\n",
      "Iteration 10, loss = 0.47231576\n",
      "Iteration 11, loss = 0.46547249\n",
      "Iteration 12, loss = 0.44229641\n",
      "Iteration 13, loss = 0.43744559\n",
      "Iteration 14, loss = 0.41939457\n",
      "Iteration 15, loss = 0.40599263\n",
      "Iteration 16, loss = 0.39745821\n",
      "Iteration 17, loss = 0.40106199\n",
      "Iteration 18, loss = 0.41118765\n",
      "Iteration 19, loss = 0.39892509\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.62860914\n",
      "Iteration 2, loss = 0.70857255\n",
      "Iteration 3, loss = 0.66092880\n",
      "Iteration 4, loss = 0.60342523\n",
      "Iteration 5, loss = 0.57942384\n",
      "Iteration 6, loss = 0.54400600\n",
      "Iteration 7, loss = 0.52670654\n",
      "Iteration 8, loss = 0.50297517\n",
      "Iteration 9, loss = 0.47706069\n",
      "Iteration 10, loss = 0.45682344\n",
      "Iteration 11, loss = 0.43720192\n",
      "Iteration 12, loss = 0.42380076\n",
      "Iteration 13, loss = 0.41165667\n",
      "Iteration 14, loss = 0.39991733\n",
      "Iteration 15, loss = 0.39753980\n",
      "Iteration 16, loss = 0.38243618\n",
      "Iteration 17, loss = 0.37708008\n",
      "Iteration 18, loss = 0.36681478\n",
      "Iteration 19, loss = 0.36218217\n",
      "Iteration 20, loss = 0.35565749\n",
      "Iteration 21, loss = 0.36657653\n",
      "Iteration 22, loss = 0.35893024\n",
      "Iteration 23, loss = 0.36515169\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.45706245\n",
      "Iteration 2, loss = 0.71038912\n",
      "Iteration 3, loss = 0.63434319\n",
      "Iteration 4, loss = 0.57416703\n",
      "Iteration 5, loss = 0.54326913\n",
      "Iteration 6, loss = 0.51460006\n",
      "Iteration 7, loss = 0.49684221\n",
      "Iteration 8, loss = 0.47533688\n",
      "Iteration 9, loss = 0.44878077\n",
      "Iteration 10, loss = 0.43107861\n",
      "Iteration 11, loss = 0.42270668\n",
      "Iteration 12, loss = 0.40561525\n",
      "Iteration 13, loss = 0.40540744\n",
      "Iteration 14, loss = 0.40492050\n",
      "Iteration 15, loss = 0.39785483\n",
      "Iteration 16, loss = 0.42803006\n",
      "Iteration 17, loss = 0.43442411\n",
      "Iteration 18, loss = 0.40896967\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.8513161 , 0.88261797, 0.8359023 , 0.85605881, 0.84372777])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(mlpc_1, X_train_small, y_train_small_m, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
