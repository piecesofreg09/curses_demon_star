{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import all the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import pickle, os, math\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data from the data folder. This step only uses the data for surviving in the rain of topedoes for the fighter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200036, 24)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.path.join(os.curdir, 'Data', '200000_sur', 'basic_data_pics.pkl')\n",
    "with open(data_dir, 'rb') as in_file:\n",
    "    ot = pickle.load(in_file)\n",
    "data_pics = ot['data']\n",
    "target_pics = ot['target']\n",
    "data_pics.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first raw data is unbalanced with classes. The ratio of classes 0 and 1 are almost 1:10. Very unbalanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_pics, target_pics, test_size=0.1, random_state=152)\n",
    "X_train.shape\n",
    "X_train_train, X_vali, y_train_train, y_vali = train_test_split(\n",
    "    X_train, y_train, test_size=0.3, random_state=15545)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 has 15061 points\n",
      "class 1 has 164971 points\n"
     ]
    }
   ],
   "source": [
    "print('class 0 has ' + str(len(y_train.index[y_train[0] == 0].tolist())) + ' points')\n",
    "print('class 1 has ' + str(len(y_train.index[y_train[0] == 1].tolist())) + ' points')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create balanced classes sample data, each class has 15061 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15061\n",
      "15061\n",
      "30122\n"
     ]
    }
   ],
   "source": [
    "index_0 = y_train.index[y_train[0] == 0].tolist()\n",
    "print(len(index_0))\n",
    "index_1 = y_train.index[y_train[0] != 0].tolist()\n",
    "index_1_comparable_to_0 = np.random.choice(index_1, math.floor(len(index_0) * 1))\n",
    "print(len(index_1_comparable_to_0))\n",
    "samples = np.concatenate([index_0, index_1_comparable_to_0])\n",
    "print(len(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`small_data` and `small_target` are the balanced data. All variables with `_small` is the balanced result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = data_pics.iloc[samples, :]\n",
    "small_target = target_pics.iloc[samples, :]\n",
    "\n",
    "X_train_small, X_test_small, y_train_small, y_test_small = train_test_split(\n",
    "    small_data, small_target, test_size=0.3, random_state=152)\n",
    "X_train_train_small, X_vali_small, y_train_train_small, y_vali_small = train_test_split(\n",
    "    X_train_small, y_train_small, test_size=0.3, random_state=152)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pretraining Several Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the scikit models, target (y) has to be ravelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_small_m = np.ravel(y_train_small)\n",
    "y_test_small_m = np.ravel(y_test_small)\n",
    "y_train_m = np.ravel(y_train)\n",
    "y_test_m = np.ravel(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 SVC with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9391390948323559"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_1 = SVC(C=10.0, gamma='auto', verbose=True)\n",
    "clf_1.fit(X_train_small, y_train_small_m)\n",
    "clf_1.score(X_test_small, y_test_small_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.943101  , 0.93454752, 0.93625498, 0.93284007, 0.94023904,\n",
       "       0.94280023])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf_1, X_train_small, y_train_small_m, cv=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 MLPC with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8528272656855151"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpc_1 = MLPClassifier(hidden_layer_sizes=(50, 20),\n",
    "                       alpha=0.15, max_iter=1000, batch_size=5000,\n",
    "                       verbose=False, learning_rate_init=0.01, tol=1e-5,\n",
    "                       learning_rate='adaptive')\n",
    "\n",
    "mlpc_1.fit(X_train_small, y_train_small_m)\n",
    "mlpc_1.score(X_test_small, y_test_small_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86744131, 0.81550866, 0.88617501, 0.66137064, 0.68840408])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(mlpc_1, X_train_small, y_train_small_m, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 NN with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\hlu82\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\users\\hlu82\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 14759 samples, validate on 6326 samples\n",
      "Epoch 1/20\n",
      "14759/14759 [==============================] - 0s 16us/step - loss: 0.2037 - acc: 0.7028 - val_loss: 0.1907 - val_acc: 0.7120\n",
      "Epoch 2/20\n",
      "14759/14759 [==============================] - 0s 5us/step - loss: 0.1784 - acc: 0.7353 - val_loss: 0.1737 - val_acc: 0.7404\n",
      "Epoch 3/20\n",
      "14759/14759 [==============================] - 0s 5us/step - loss: 0.1634 - acc: 0.7585 - val_loss: 0.1613 - val_acc: 0.7883\n",
      "Epoch 4/20\n",
      "14759/14759 [==============================] - 0s 5us/step - loss: 0.1489 - acc: 0.7917 - val_loss: 0.1494 - val_acc: 0.7700\n",
      "Epoch 5/20\n",
      "14759/14759 [==============================] - 0s 5us/step - loss: 0.1371 - acc: 0.8221 - val_loss: 0.1407 - val_acc: 0.7882\n",
      "Epoch 6/20\n",
      "14759/14759 [==============================] - 0s 5us/step - loss: 0.1266 - acc: 0.8499 - val_loss: 0.1284 - val_acc: 0.8332\n",
      "Epoch 7/20\n",
      "14759/14759 [==============================] - 0s 7us/step - loss: 0.1179 - acc: 0.8593 - val_loss: 0.1186 - val_acc: 0.8506\n",
      "Epoch 8/20\n",
      "14759/14759 [==============================] - 0s 5us/step - loss: 0.1119 - acc: 0.8656 - val_loss: 0.1121 - val_acc: 0.8610\n",
      "Epoch 9/20\n",
      "14759/14759 [==============================] - 0s 5us/step - loss: 0.1067 - acc: 0.8726 - val_loss: 0.1107 - val_acc: 0.8702\n",
      "Epoch 10/20\n",
      "14759/14759 [==============================] - 0s 5us/step - loss: 0.1030 - acc: 0.8764 - val_loss: 0.1064 - val_acc: 0.8617\n",
      "Epoch 11/20\n",
      "14759/14759 [==============================] - 0s 5us/step - loss: 0.0993 - acc: 0.8806 - val_loss: 0.1033 - val_acc: 0.8758\n",
      "Epoch 12/20\n",
      "14759/14759 [==============================] - 0s 5us/step - loss: 0.0972 - acc: 0.8823 - val_loss: 0.0987 - val_acc: 0.8786\n",
      "Epoch 13/20\n",
      "14759/14759 [==============================] - 0s 5us/step - loss: 0.0958 - acc: 0.8824 - val_loss: 0.0976 - val_acc: 0.8814\n",
      "Epoch 14/20\n",
      "14759/14759 [==============================] - 0s 5us/step - loss: 0.0934 - acc: 0.8852 - val_loss: 0.0952 - val_acc: 0.8865\n",
      "Epoch 15/20\n",
      "14759/14759 [==============================] - 0s 5us/step - loss: 0.0917 - acc: 0.8874 - val_loss: 0.0980 - val_acc: 0.8788\n",
      "Epoch 16/20\n",
      "14759/14759 [==============================] - 0s 5us/step - loss: 0.0895 - acc: 0.8903 - val_loss: 0.0913 - val_acc: 0.8889\n",
      "Epoch 17/20\n",
      "14759/14759 [==============================] - 0s 5us/step - loss: 0.0880 - acc: 0.8910 - val_loss: 0.0904 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "14759/14759 [==============================] - 0s 5us/step - loss: 0.0869 - acc: 0.8934 - val_loss: 0.0889 - val_acc: 0.8927\n",
      "Epoch 19/20\n",
      "14759/14759 [==============================] - 0s 5us/step - loss: 0.0855 - acc: 0.8951 - val_loss: 0.0862 - val_acc: 0.8939\n",
      "Epoch 20/20\n",
      "14759/14759 [==============================] - 0s 5us/step - loss: 0.0843 - acc: 0.8966 - val_loss: 0.0873 - val_acc: 0.8886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x258df4e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_NNK = Sequential()\n",
    "model_NNK.add(Dense(units=12, activation='relu', input_dim=24))\n",
    "model_NNK.add(Dense(units=6, activation='relu'))\n",
    "model_NNK.add(Dense(units=1, activation='sigmoid'))\n",
    "model_NNK.compile(loss='mean_squared_error',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_NNK.fit(X_train_train_small, y_train_train_small,\n",
    "          validation_data=(X_vali_small, y_vali_small), \n",
    "          epochs=20, batch_size=256, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9037/9037 [==============================] - 0s 6us/step\n",
      "[0.08583185275901375, 0.8903397143421361]\n",
      "0.46987817444948543\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model_NNK.evaluate(X_test_small, y_test_small, batch_size=128)\n",
    "print(loss_and_metrics)\n",
    "y_predict = model_NNK.predict(X_test_small, batch_size=None, verbose=0)\n",
    "print(np.sum(y_predict) / len(y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Selecting models\n",
    "\n",
    "the SVC model apparently has a higher accuracy, grid search is used to find the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C': [0.1, 1, 10], 'kernel': ['rbf', 'linear']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6, error_score='raise',\n",
       "       estimator=SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=True),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.1, 1, 10], 'kernel': ['rbf', 'linear']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "clf_2 = SVC(C=10.0, gamma='auto', verbose=True)\n",
    "svc_vc = GridSearchCV(clf_2, parameters, cv=6, refit=True)\n",
    "svc_vc.fit(X_train_small, y_train_small_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hlu82\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\hlu82\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\hlu82\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\hlu82\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\hlu82\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\hlu82\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split5_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\hlu82\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\hlu82\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 6.52448571,  6.30663069,  6.09377599, 12.40724055,  7.36623653,\n",
       "        60.76290898]),\n",
       " 'std_fit_time': array([0.41663224, 0.25077265, 0.19768908, 0.56153832, 0.44656144,\n",
       "        3.58722979]),\n",
       " 'mean_score_time': array([0.69106905, 0.34920148, 0.53855387, 0.36386979, 0.46838025,\n",
       "        0.36653662]),\n",
       " 'std_score_time': array([0.02388407, 0.01261624, 0.04772186, 0.02875132, 0.02333083,\n",
       "        0.02490056]),\n",
       " 'param_C': masked_array(data=[0.1, 0.1, 1, 1, 10, 10],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear'],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'kernel': 'linear'},\n",
       "  {'C': 10, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'kernel': 'linear'}],\n",
       " 'split0_test_score': array([0.91209104, 0.885633  , 0.93229018, 0.885633  , 0.943101  ,\n",
       "        0.885633  ]),\n",
       " 'split1_test_score': array([0.90409789, 0.88104724, 0.92601024, 0.88104724, 0.93454752,\n",
       "        0.88104724]),\n",
       " 'split2_test_score': array([0.90295959, 0.87763233, 0.92373364, 0.87763233, 0.93625498,\n",
       "        0.87763233]),\n",
       " 'split3_test_score': array([0.90381332, 0.88190097, 0.92316448, 0.88190097, 0.93284007,\n",
       "        0.88190097]),\n",
       " 'split4_test_score': array([0.91064314, 0.88417758, 0.93682413, 0.88417758, 0.94023904,\n",
       "        0.88417758]),\n",
       " 'split5_test_score': array([0.90922026, 0.88417758, 0.93056346, 0.88417758, 0.94280023,\n",
       "        0.88417758]),\n",
       " 'mean_test_score': array([0.90713778, 0.88242827, 0.92876452, 0.88242827, 0.93829737,\n",
       "        0.88242827]),\n",
       " 'std_test_score': array([0.00362658, 0.00263242, 0.00491387, 0.00263242, 0.00398199,\n",
       "        0.00263242]),\n",
       " 'rank_test_score': array([3, 4, 2, 4, 1, 4]),\n",
       " 'split0_train_score': array([0.90802504, 0.88178714, 0.93244166, 0.88178714, 0.9479226 ,\n",
       "        0.88178714]),\n",
       " 'split1_train_score': array([0.90996528, 0.88270446, 0.93386831, 0.88270446, 0.94946218,\n",
       "        0.88270446]),\n",
       " 'split2_train_score': array([0.90899778, 0.8833874 , 0.93415287, 0.8833874 , 0.9480963 ,\n",
       "        0.8833874 ]),\n",
       " 'split3_train_score': array([0.90933925, 0.88412726, 0.93438051, 0.88412726, 0.94968983,\n",
       "        0.88412726]),\n",
       " 'split4_train_score': array([0.90711969, 0.88145239, 0.93420978, 0.88145239, 0.94900689,\n",
       "        0.88145239]),\n",
       " 'split5_train_score': array([0.90797337, 0.88168004, 0.93307154, 0.88168004, 0.94917762,\n",
       "        0.88168004]),\n",
       " 'mean_train_score': array([0.90857007, 0.88252311, 0.93368744, 0.88252311, 0.94889257,\n",
       "        0.88252311]),\n",
       " 'std_train_score': array([0.0009555 , 0.00097912, 0.00069926, 0.00097912, 0.00066198,\n",
       "        0.00097912])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_vc.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9391390948323559"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_1.score(X_test_small, y_test_small_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "svc_best = svc_vc.best_estimator_\n",
    "joblib.dump(svc_best, 'model_svc_survive.joblib')\n",
    "svc_best_loaded = joblib.load('model_svc_survive.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_best_loaded.predict([X_test_small.iloc[0, :]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
